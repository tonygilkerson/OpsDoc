{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to OpsDoc Here you will find my personal Ops related notes.","title":"Home"},{"location":"#welcome-to-opsdoc","text":"Here you will find my personal Ops related notes.","title":"Welcome to OpsDoc"},{"location":"about/","text":"This is my personal notes Ops related stuff.","title":"About"},{"location":"mon-log-scale/","text":"Introduction This section contains notes taken when reading through The DevOps 2.5 Toolkit book. At this time I am working through the Collecting and Querying Metrics and Sending Alerts chapter and don't have much to add beyond what is contained in this gist","title":"Monitoring"},{"location":"mon-log-scale/#introduction","text":"This section contains notes taken when reading through The DevOps 2.5 Toolkit book. At this time I am working through the Collecting and Querying Metrics and Sending Alerts chapter and don't have much to add beyond what is contained in this gist","title":"Introduction"},{"location":"ref/","text":"Kubernetes Docker Desktop Dashboard Install dashboard #install kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml #open kubectl proxy open http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ logon DASH_SECRET=$(kubectl get serviceAccounts -o jsonpath=\"{.items[0].secrets[0].name}\") # cut/past the token shown form this command kubectl describe secrets/$DASH_SECRET charts and graphs This stuff is optional but will make charts and graphs show up in the dashboard. kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml Heapster workaround: I got an error where heapster could not connect so I had to edit the --source value for the deployment as shown below { \"kind\": \"Deployment\", \"apiVersion\": \"extensions/v1beta1\", \"metadata\": { \"name\": \"heapster\", \"namespace\": \"kube-system\", ..., \"spec\": { \"containers\": [ { ... \"command\": [ \"/heapster\", ====> \"--source=kubernetes:https://kubernetes.default:443?useServiceAccount=true&kubeletHttps=true&kubeletPort=10250&insecure=true\", \"--sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086\" ], ... ... } For more information see: Setup: https://github.com/kubernetes/dashboard this blog post Configure access: https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#accessing-the-dashboard-ui https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/ Kubernetes API Doc Kubernetes API Bash scripting cheatsheet Dev Hints The DevOps 2.3 Toolkit: Kubernetes 02-minikube.sh 03-pod.hs 04-rs.sh 05-svc.sh 06-deploy.sh 07-ingress.sh 08-volume.sh 09-config-map.sh 10-secret.sh 11-ns.sh 12-auth.sh 13-resource.sh 14-aws.sh 15-pv.sh","title":"Reference"},{"location":"ref/#kubernetes","text":"","title":"Kubernetes"},{"location":"ref/#docker-desktop-dashboard","text":"Install dashboard #install kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml #open kubectl proxy open http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ logon DASH_SECRET=$(kubectl get serviceAccounts -o jsonpath=\"{.items[0].secrets[0].name}\") # cut/past the token shown form this command kubectl describe secrets/$DASH_SECRET charts and graphs This stuff is optional but will make charts and graphs show up in the dashboard. kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml Heapster workaround: I got an error where heapster could not connect so I had to edit the --source value for the deployment as shown below { \"kind\": \"Deployment\", \"apiVersion\": \"extensions/v1beta1\", \"metadata\": { \"name\": \"heapster\", \"namespace\": \"kube-system\", ..., \"spec\": { \"containers\": [ { ... \"command\": [ \"/heapster\", ====> \"--source=kubernetes:https://kubernetes.default:443?useServiceAccount=true&kubeletHttps=true&kubeletPort=10250&insecure=true\", \"--sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086\" ], ... ... } For more information see: Setup: https://github.com/kubernetes/dashboard this blog post Configure access: https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#accessing-the-dashboard-ui https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/","title":"Docker Desktop Dashboard"},{"location":"ref/#kubernetes-api-doc","text":"Kubernetes API","title":"Kubernetes API Doc"},{"location":"ref/#bash-scripting-cheatsheet","text":"Dev Hints","title":"Bash scripting cheatsheet"},{"location":"ref/#the-devops-23-toolkit-kubernetes","text":"02-minikube.sh 03-pod.hs 04-rs.sh 05-svc.sh 06-deploy.sh 07-ingress.sh 08-volume.sh 09-config-map.sh 10-secret.sh 11-ns.sh 12-auth.sh 13-resource.sh 14-aws.sh 15-pv.sh","title":"The DevOps 2.3 Toolkit: Kubernetes"},{"location":"cicd/cicd-toolkit24/","text":"Introduction This sections contains the notes taken while reading The DevOps 2.4 Toolkit . References to page numbers are assumed to be from this book unless otherwise specified. Create a cluster Docker for Windows Follow the docker-for-windows doc to create a cluster on a windows workstation. Kubernetes dashboard The full instructions can be found on the Kubernetes dashboard readme page , in short, run the following: kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml Accessing the dashboard UI Run kubectl proxy then open http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ in your browser. To log onto the UI you will need a token. Do the following to get a valid token: SECRET_NAME=$(kubectl -n kube-system \\ get serviceAccount kubernetes-dashboard \\ -o jsonpath='{.secrets[0].name}') kubectl -n kube-system describe secrets/$SECRET_NAME # copy token from the output and use it to log onto the dashboard For more informatoin on how to configure access see the following: Accessing the dashboard UI Configure Service Account Ingress Install I got the ingress to work fine on docker-for-win by following the install instructions for mac , in short, run the following: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/cloud-generic.yaml Define Some Environment Variables To make live easy let set some environment variables for our shell: LB_IP Find your loadBalancer IP: On docker-for-windows this is 127.0.0.1 for other cluster you can try the following: Update - I think it might be better to use the IP of my laptop i.e. 192.168.1.164 . This might make is so the pod to pod communication works. I am not sure. The later 2.5 book started doing this. I keep the notes here point to the loopback interface because that is what I used but if I go back through this a second time I should try my laptop IP and if all works out update this doc. kubectl -n ingress-nginx get svc ingress-nginx -o jsonpath=\"{.status.loadBalancer.ingress[0].hostname}\" #or kubectl -n ingress-nginx get svc ingress-nginx -o jsonpath=\"{.status.loadBalancer.ingress[0].ip}\" # set it LB_IP=\"127.0.0.1\" # or make it stick do this echo \"export LB_IP=127.0.0.1\" >> ~/.profile . ~/.profile ADDR ADDR=$LB_IP.nip.io echo $ADDR ADDR_ESC=$(echo $ADDR | sed -e \"s@\\.@\\\\\\.@g\") echo $ADDR_ESC # or make it stick do this echo \"export ADDR=$LB_IP.nip.io\" >> ~/.profile echo 'ADDR_ESC=$(echo $ADDR | sed -e \"s@\\.@\\\\\\.@g\")' >> ~/.profile . ~/.profile DH_USER Docker Hub user DH_USER=\"tonygilkerson\" echo \"export DH_USER=tonygilkerson\" >> ~/.profile . ~/.profile echo $DH_USER Client Tools kubectl Follow the Install and Setup kubectl instructions on the official kubernetes site. helm Currently helm v2 needs tiller, when we get to v3 tiller will go away. To install tiller: cd k8s-spec # Create service account kubectl create \\ -f helm/tiller-rbac.yml # Install server side tiller helm init --service-account tiller # verify kubectl -n kube-system \\ rollout status deploy tiller-deploy Chart Museum Install Chart Install stable/chartmuseum chart with override values (p. 130). cd kube-spec # set chartmuseum host env vars echo $LB_IP CM_ADDR=\"cm.$LB_IP.nip.io\" CM_ADDR_ESC=$(echo $CM_ADDR | sed -e \"s@\\.@\\\\\\.@g\") echo $CM_ADDR_ESC # install chart helm install stable/chartmuseum \\ --namespace charts \\ --name cm \\ --values helm/chartmuseum-values.yml \\ --set ingress.hosts.\"$CM_ADDR_ESC\"={\"/\"} \\ --set env.secret.BASIC_AUTH_USER=admin \\ --set env.secret.BASIC_AUTH_PASS=admin # verify kubectl -n charts \\ rollout status deploy \\ cm-chartmuseum curl \"http://$CM_ADDR/health\" curl \"http://$CM_ADDR/index.yaml\" -u admin:admin Add to helm client Add the chartmuseum repo to the helm client, then install a plugin that will allow us to push charts to the repo via helm CLI. helm repo add chartmuseum http://$CM_ADDR --username admin --password admin helm plugin install https://github.com/chartmuseum/helm-push # example push helm push /path/to/chart chartmuseum --username admin --password admin # we can also do this helm search chartmuseum/ helm repo update helm search chartmuseum/ helm inspect chartmuseum/<my-chart> More useful command can be found at vfarcic gist Upgrade To upgrade after modifying values. helm upgrade cm stable/chartmuseum \\ --values helm/chartmuseum-values.yml \\ --set ingress.hosts.\"$CM_ADDR_ESC\"={\"/\"} \\ --set env.secret.BASIC_AUTH_USER=admin \\ --set env.secret.BASIC_AUTH_PASS=admin Accessing the UI To access chartmuseum from my laptop I use $CM_ADDR as seen above however this is not valid in a pipeline build container. From within a container use the http://[SERVICE_NAME].[NAMESPACE] format as seen here: # from within the cluster, pod to pod http://cm-chartmuseum.charts:8080 # from my browser http://cm.127.0.0.1.nip.io Jenkins Install Install stable/jenkins chart with override values (p. 130). cd kube-spec # set jenkins host env vars echo $LB_IP JENKINS_ADDR=\"jenkins.$LB_IP.nip.io\" echo $JENKINS_ADDR # install jenkins (p. 135 and p. 179) helm install stable/jenkins \\ --name jenkins \\ --namespace jenkins \\ --values helm/jenkins-values.yml \\ --set Master.HostName=$JENKINS_ADDR # verify kubectl -n jenkins rollout status deployment jenkins open http://$JENKINS_ADDR/configure (i.e. http://jenkins.127.0.0.1.nip.io) use the JENKINS_PASS to logon as admin . JENKINS_PASS=$(kubectl -n jenkins get secret jenkins \\ -o jsonpath=\"{.data.jenkins-admin-password}\" | base64 --decode) echo $JENKINS_PASS Namespace URLs To allow communication between the Jenkins master and the slave nodes in other namespaces open http://$JENKINS_ADDR/configure and change the http://[NAMESPACE] format to the http://[SERVICE_NAME].[NAMESPACE] as shown in the following table. Cloud->Kubernetes Section: label old values updated value Jenkins URL http://jenkins:8080 http://jenkins.jenkins:8080 Jenkins tunnel jenkins-agent:50000 jenkins-agent.jenkins:50000 Tiller Note: We have Tiller running in the kube-system Namespace. However, our agent Pods running in <app-namespace> do not have permissions to access it. We could extend the permissions, but that would allow the pods in that Namespace to gain almost complete control over the whole cluster. Unless your organization is very small, that is often not acceptable. Instead, we\u2019ll deploy another Tiller instance in the <app-namespace> namespace and tie it to the build ServiceAccount. That will give the new tiller the same permissions in the <app-namespace> namespace. It\u2019ll be able to do anything in those, but nothing anywhere else (p. 195). helm init --service-account build --tiller-namespace <app-namespace> RBAC This next section I am not so sure about. Docker-for-windows does not seem to use the rbac, so I will have to validate the following in a real cluster. Add rbac for jenkins builds. kubectl apply -f k8s/ns.yml Global Pipeline Libraries Open http://jenkins.$ADDR/configure Search for Global Pipeline Libraries section of the configuration, and click the Add button. Type my-library as the Name (it can be anything else) and master as the Default version. In our context, the latter defines the branch from which we\u2019ll load the libraries. Next, we\u2019ll click the Load implicitly checkbox. As a result, the libraries will be available automatically to all the pipeline jobs. Otherwise, our jobs would need to have @Library('my-library') instruction. Select Modern SCM from the Retrieval method section and select Git from Source Code Management and then specify the repository from which Jenkins will load the libraries https://github.com/tgilkerson/jenkins-shared-libraries.git Don\u2019t forget to click the Save button to persist the changes! Global credentials Select Credentials and in the global store for the Jenkins scope, then click to Add Credentials Docker Hub scope: Global Username: tonygilkerson Password: mypwd ID: docker Chart Museum scope: Global Username: admin Password: admin ID: chartmuseum Upgrade Jenkins To upgrade after modifying values in helm/jenkins-values.yml (pg126) helm upgrade jenkins stable/jenkins \\ --values helm/jenkins-values.yml \\ --set Master.HostName=$HOST \\ --reuse-values Prepare Apps go-demo-5 cd go-demo-5 kubectl apply -f k8s/build.yml # do once then commit changes cat Jenkinsfile.orig \\ | sed -e \"s@acme.com@$ADDR@g\" \\ | sed -e \"s@vfarcic@$DH_USER@g\" \\ | tee Jenkinsfile # do once then commit changes cat helm/go-demo-5/deployment-orig.yaml \\ | sed -e \"s@vfarcic@$DH_USER@g\" \\ | tee helm/go-demo-5/templates/deployment.yaml git add . git commit -m \"set docker hub user\" git push Install Tiller for this app helm init --service-account build \\ --tiller-namespace go-demo-5-build Create Jenkins Cloud for this App If you look in the Jenkinsfile you will see a reference to go-demo5-build . cd go-demo-5 cat Jenkinsfile ... agent { kubernetes { cloud \"go-demo-5-build\" label \"go-demo-5-build\" serviceAccount \"build\" yamlFile \"KubernetesPod.yaml\" } ... To configure the cloud open the Jenkins UI and navigate to the /configure page. Please scroll to the bottom of the page, expand the Add a new cloud list, and select Kubernetes . A new set of fields will appear. Type go-demo-5-build as the name. It matches the cloud entry inside kubernetes block of our pipeline. Next, type go-demo-5-build as the Kubernetes Namespace. Just as with the other Kubernetes Cloud that was already defined in our Jenkins instance, the value of the Jenkins URL should be http://prod-jenkins.prod:8080 , and the Jenkins tunnel should be set to prod-jenkins-agent.prod:50000 . Sandbox To test a release: SANDBOX_ADDR=\"go-demo-5-sandbox.$ADDR\" helm install helm/go-demo-5 --name go-demo-5-sandbox --namespace go-demo-5-sandbox # when done helm delete go-demo-5-sandbox --purge TODO add verification steps aegjxnode cd aegjxnode kubectl apply -f k8s/build.yml # edit Jenkinsfile and set correct values for the environment section ... environment { image = \"tonygilkerson/aegjxnode\" project = \"aegjxnode-build\" domain = \"127.0.0.1.nip.io\" cmAddr = \"cm-chartmuseum.charts:8080\" } ... # make it stick git add . git commit -m \"set docker hub user\" git push Install Tiller for this app helm init --service-account build \\ --tiller-namespace aegjxnode-build Create Jenkins Cloud for this App If you look in the Jenkinsfile you will see a reference to aegjxnode-build . cd aegjxnode cat Jenkinsfile ... agent { kubernetes { cloud \"aegjxnode-build\" label \"aegjxnode-build\" serviceAccount \"build\" yamlFile \"KubernetesPod.yaml\" } ... To configure the cloud open the Jenkins UI and navigate to the /configure page. Please scroll to the bottom of the page, expand the Add a new cloud list, and select Kubernetes . A new set of fields will appear. Type aegjxnode-build as the name. It matches the cloud entry inside kubernetes block of our pipeline. Next, type aegjxnode-build as the Kubernetes Namespace. Just as with the other Kubernetes Cloud that was already defined in our Jenkins instance, the value of the Jenkins URL should be http://prod-jenkins.prod:8080 , and the Jenkins tunnel should be set to prod-jenkins-agent.prod:50000 . Sandbox To test a release: TODO - refer to step above once they quit changing TODO add verification steps Deploy Environment One or more apps are owned by a team. Each team has a production environment such as team1-pord . The chart in the helm folder will reference all the apps that are required for this environment in requirements.yaml Manual Deploy Clone the environment chart and review the values. git clone https://github.com/tgilkerson/team1-prod.git cd team1-prod ls -l helm Verify the host address is correct in helm/values.yaml . go-demo-5: ingress: host: go-demo-5.127.0.0.1.nip.io aegjxnode: ingress: host: aegjxnode.127.0.0.1.nip.io Later on, we\u2019ll use Jenkins to install (or upgrade) the Chart, so we should push the changes to GitHub. git add . git commit -m \"Fix the address\" git push All Helm dependencies need to be downloaded to the charts directory before they are installed. We\u2019ll do that through the helm dependency update command. Don\u2019t worry if some of the repositories are not reachable. You might see messages stating that Helm was unable to get an update from local or chartmuseum repositories. First lets do a manually deploy of the team1-prod environment. cd team1-prod helm dependency update helm ls helm/charts/ # To confirm ls -l helm/charts # The output should look like this aegjxnode-0.1.9.tgz go-demo-5-0.0.1.tgz # The first time helm install helm --name team1-prod --namespace team1-prod # Or do this the -i will install if it does not exist helm upgrade -i team1-prod helm --namespace team1-prod # verify kubectl -n team1-prod rollout status deploy team1-prod-go-demo-5 curl go-demo-5.127.0.0.1.nip.io/demo/hello # clean up helm list helm delete team1-prod --purge Auto Deploy The CI/CD pipeline will automate the manual steps above. JeninsX JenkinsX was not in the book, it is too new, however I did look into it a bit to take a look at their workflow. To install on my docker-for-windows cluster: Taken from getting started jx install --provider=kubernetes --on-premise Jenkins X installation completed successfully Your admin password is: =rvC9qvz0fq9is^Z6SwY -------------------------------------------------------------------------------- # Utility Some utility functions and other useful stuff to help debug. ```bash kubectl -n <target-namespace> run -it \\ --image ubuntu aegutil --restart=Never --rm sh # then you can... apt-get update apt-get install curl apt-get install iputils-ping","title":"Toolkit 2.4 CI/CD"},{"location":"cicd/cicd-toolkit24/#introduction","text":"This sections contains the notes taken while reading The DevOps 2.4 Toolkit . References to page numbers are assumed to be from this book unless otherwise specified.","title":"Introduction"},{"location":"cicd/cicd-toolkit24/#create-a-cluster","text":"","title":"Create a cluster"},{"location":"cicd/cicd-toolkit24/#docker-for-windows","text":"Follow the docker-for-windows doc to create a cluster on a windows workstation.","title":"Docker for Windows"},{"location":"cicd/cicd-toolkit24/#kubernetes-dashboard","text":"The full instructions can be found on the Kubernetes dashboard readme page , in short, run the following: kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml","title":"Kubernetes dashboard"},{"location":"cicd/cicd-toolkit24/#accessing-the-dashboard-ui","text":"Run kubectl proxy then open http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ in your browser. To log onto the UI you will need a token. Do the following to get a valid token: SECRET_NAME=$(kubectl -n kube-system \\ get serviceAccount kubernetes-dashboard \\ -o jsonpath='{.secrets[0].name}') kubectl -n kube-system describe secrets/$SECRET_NAME # copy token from the output and use it to log onto the dashboard For more informatoin on how to configure access see the following: Accessing the dashboard UI Configure Service Account","title":"Accessing the dashboard UI"},{"location":"cicd/cicd-toolkit24/#ingress-install","text":"I got the ingress to work fine on docker-for-win by following the install instructions for mac , in short, run the following: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/cloud-generic.yaml","title":"Ingress Install"},{"location":"cicd/cicd-toolkit24/#define-some-environment-variables","text":"To make live easy let set some environment variables for our shell: LB_IP Find your loadBalancer IP: On docker-for-windows this is 127.0.0.1 for other cluster you can try the following: Update - I think it might be better to use the IP of my laptop i.e. 192.168.1.164 . This might make is so the pod to pod communication works. I am not sure. The later 2.5 book started doing this. I keep the notes here point to the loopback interface because that is what I used but if I go back through this a second time I should try my laptop IP and if all works out update this doc. kubectl -n ingress-nginx get svc ingress-nginx -o jsonpath=\"{.status.loadBalancer.ingress[0].hostname}\" #or kubectl -n ingress-nginx get svc ingress-nginx -o jsonpath=\"{.status.loadBalancer.ingress[0].ip}\" # set it LB_IP=\"127.0.0.1\" # or make it stick do this echo \"export LB_IP=127.0.0.1\" >> ~/.profile . ~/.profile ADDR ADDR=$LB_IP.nip.io echo $ADDR ADDR_ESC=$(echo $ADDR | sed -e \"s@\\.@\\\\\\.@g\") echo $ADDR_ESC # or make it stick do this echo \"export ADDR=$LB_IP.nip.io\" >> ~/.profile echo 'ADDR_ESC=$(echo $ADDR | sed -e \"s@\\.@\\\\\\.@g\")' >> ~/.profile . ~/.profile DH_USER Docker Hub user DH_USER=\"tonygilkerson\" echo \"export DH_USER=tonygilkerson\" >> ~/.profile . ~/.profile echo $DH_USER","title":"Define Some Environment Variables"},{"location":"cicd/cicd-toolkit24/#client-tools","text":"","title":"Client Tools"},{"location":"cicd/cicd-toolkit24/#kubectl","text":"Follow the Install and Setup kubectl instructions on the official kubernetes site.","title":"kubectl"},{"location":"cicd/cicd-toolkit24/#helm","text":"Currently helm v2 needs tiller, when we get to v3 tiller will go away. To install tiller: cd k8s-spec # Create service account kubectl create \\ -f helm/tiller-rbac.yml # Install server side tiller helm init --service-account tiller # verify kubectl -n kube-system \\ rollout status deploy tiller-deploy","title":"helm"},{"location":"cicd/cicd-toolkit24/#chart-museum","text":"","title":"Chart Museum"},{"location":"cicd/cicd-toolkit24/#install-chart","text":"Install stable/chartmuseum chart with override values (p. 130). cd kube-spec # set chartmuseum host env vars echo $LB_IP CM_ADDR=\"cm.$LB_IP.nip.io\" CM_ADDR_ESC=$(echo $CM_ADDR | sed -e \"s@\\.@\\\\\\.@g\") echo $CM_ADDR_ESC # install chart helm install stable/chartmuseum \\ --namespace charts \\ --name cm \\ --values helm/chartmuseum-values.yml \\ --set ingress.hosts.\"$CM_ADDR_ESC\"={\"/\"} \\ --set env.secret.BASIC_AUTH_USER=admin \\ --set env.secret.BASIC_AUTH_PASS=admin # verify kubectl -n charts \\ rollout status deploy \\ cm-chartmuseum curl \"http://$CM_ADDR/health\" curl \"http://$CM_ADDR/index.yaml\" -u admin:admin","title":"Install Chart"},{"location":"cicd/cicd-toolkit24/#add-to-helm-client","text":"Add the chartmuseum repo to the helm client, then install a plugin that will allow us to push charts to the repo via helm CLI. helm repo add chartmuseum http://$CM_ADDR --username admin --password admin helm plugin install https://github.com/chartmuseum/helm-push # example push helm push /path/to/chart chartmuseum --username admin --password admin # we can also do this helm search chartmuseum/ helm repo update helm search chartmuseum/ helm inspect chartmuseum/<my-chart> More useful command can be found at vfarcic gist","title":"Add to helm client"},{"location":"cicd/cicd-toolkit24/#upgrade","text":"To upgrade after modifying values. helm upgrade cm stable/chartmuseum \\ --values helm/chartmuseum-values.yml \\ --set ingress.hosts.\"$CM_ADDR_ESC\"={\"/\"} \\ --set env.secret.BASIC_AUTH_USER=admin \\ --set env.secret.BASIC_AUTH_PASS=admin","title":"Upgrade"},{"location":"cicd/cicd-toolkit24/#accessing-the-ui","text":"To access chartmuseum from my laptop I use $CM_ADDR as seen above however this is not valid in a pipeline build container. From within a container use the http://[SERVICE_NAME].[NAMESPACE] format as seen here: # from within the cluster, pod to pod http://cm-chartmuseum.charts:8080 # from my browser http://cm.127.0.0.1.nip.io","title":"Accessing the UI"},{"location":"cicd/cicd-toolkit24/#jenkins","text":"","title":"Jenkins"},{"location":"cicd/cicd-toolkit24/#install","text":"Install stable/jenkins chart with override values (p. 130). cd kube-spec # set jenkins host env vars echo $LB_IP JENKINS_ADDR=\"jenkins.$LB_IP.nip.io\" echo $JENKINS_ADDR # install jenkins (p. 135 and p. 179) helm install stable/jenkins \\ --name jenkins \\ --namespace jenkins \\ --values helm/jenkins-values.yml \\ --set Master.HostName=$JENKINS_ADDR # verify kubectl -n jenkins rollout status deployment jenkins open http://$JENKINS_ADDR/configure (i.e. http://jenkins.127.0.0.1.nip.io) use the JENKINS_PASS to logon as admin . JENKINS_PASS=$(kubectl -n jenkins get secret jenkins \\ -o jsonpath=\"{.data.jenkins-admin-password}\" | base64 --decode) echo $JENKINS_PASS","title":"Install"},{"location":"cicd/cicd-toolkit24/#namespace-urls","text":"To allow communication between the Jenkins master and the slave nodes in other namespaces open http://$JENKINS_ADDR/configure and change the http://[NAMESPACE] format to the http://[SERVICE_NAME].[NAMESPACE] as shown in the following table. Cloud->Kubernetes Section: label old values updated value Jenkins URL http://jenkins:8080 http://jenkins.jenkins:8080 Jenkins tunnel jenkins-agent:50000 jenkins-agent.jenkins:50000","title":"Namespace URLs"},{"location":"cicd/cicd-toolkit24/#tiller","text":"Note: We have Tiller running in the kube-system Namespace. However, our agent Pods running in <app-namespace> do not have permissions to access it. We could extend the permissions, but that would allow the pods in that Namespace to gain almost complete control over the whole cluster. Unless your organization is very small, that is often not acceptable. Instead, we\u2019ll deploy another Tiller instance in the <app-namespace> namespace and tie it to the build ServiceAccount. That will give the new tiller the same permissions in the <app-namespace> namespace. It\u2019ll be able to do anything in those, but nothing anywhere else (p. 195). helm init --service-account build --tiller-namespace <app-namespace>","title":"Tiller"},{"location":"cicd/cicd-toolkit24/#rbac","text":"This next section I am not so sure about. Docker-for-windows does not seem to use the rbac, so I will have to validate the following in a real cluster. Add rbac for jenkins builds. kubectl apply -f k8s/ns.yml","title":"RBAC"},{"location":"cicd/cicd-toolkit24/#global-pipeline-libraries","text":"Open http://jenkins.$ADDR/configure Search for Global Pipeline Libraries section of the configuration, and click the Add button. Type my-library as the Name (it can be anything else) and master as the Default version. In our context, the latter defines the branch from which we\u2019ll load the libraries. Next, we\u2019ll click the Load implicitly checkbox. As a result, the libraries will be available automatically to all the pipeline jobs. Otherwise, our jobs would need to have @Library('my-library') instruction. Select Modern SCM from the Retrieval method section and select Git from Source Code Management and then specify the repository from which Jenkins will load the libraries https://github.com/tgilkerson/jenkins-shared-libraries.git Don\u2019t forget to click the Save button to persist the changes!","title":"Global Pipeline Libraries"},{"location":"cicd/cicd-toolkit24/#global-credentials","text":"Select Credentials and in the global store for the Jenkins scope, then click to Add Credentials Docker Hub scope: Global Username: tonygilkerson Password: mypwd ID: docker Chart Museum scope: Global Username: admin Password: admin ID: chartmuseum","title":"Global credentials"},{"location":"cicd/cicd-toolkit24/#upgrade-jenkins","text":"To upgrade after modifying values in helm/jenkins-values.yml (pg126) helm upgrade jenkins stable/jenkins \\ --values helm/jenkins-values.yml \\ --set Master.HostName=$HOST \\ --reuse-values","title":"Upgrade Jenkins"},{"location":"cicd/cicd-toolkit24/#prepare-apps","text":"","title":"Prepare Apps"},{"location":"cicd/cicd-toolkit24/#go-demo-5","text":"cd go-demo-5 kubectl apply -f k8s/build.yml # do once then commit changes cat Jenkinsfile.orig \\ | sed -e \"s@acme.com@$ADDR@g\" \\ | sed -e \"s@vfarcic@$DH_USER@g\" \\ | tee Jenkinsfile # do once then commit changes cat helm/go-demo-5/deployment-orig.yaml \\ | sed -e \"s@vfarcic@$DH_USER@g\" \\ | tee helm/go-demo-5/templates/deployment.yaml git add . git commit -m \"set docker hub user\" git push Install Tiller for this app helm init --service-account build \\ --tiller-namespace go-demo-5-build Create Jenkins Cloud for this App If you look in the Jenkinsfile you will see a reference to go-demo5-build . cd go-demo-5 cat Jenkinsfile ... agent { kubernetes { cloud \"go-demo-5-build\" label \"go-demo-5-build\" serviceAccount \"build\" yamlFile \"KubernetesPod.yaml\" } ... To configure the cloud open the Jenkins UI and navigate to the /configure page. Please scroll to the bottom of the page, expand the Add a new cloud list, and select Kubernetes . A new set of fields will appear. Type go-demo-5-build as the name. It matches the cloud entry inside kubernetes block of our pipeline. Next, type go-demo-5-build as the Kubernetes Namespace. Just as with the other Kubernetes Cloud that was already defined in our Jenkins instance, the value of the Jenkins URL should be http://prod-jenkins.prod:8080 , and the Jenkins tunnel should be set to prod-jenkins-agent.prod:50000 . Sandbox To test a release: SANDBOX_ADDR=\"go-demo-5-sandbox.$ADDR\" helm install helm/go-demo-5 --name go-demo-5-sandbox --namespace go-demo-5-sandbox # when done helm delete go-demo-5-sandbox --purge TODO add verification steps","title":"go-demo-5"},{"location":"cicd/cicd-toolkit24/#aegjxnode","text":"cd aegjxnode kubectl apply -f k8s/build.yml # edit Jenkinsfile and set correct values for the environment section ... environment { image = \"tonygilkerson/aegjxnode\" project = \"aegjxnode-build\" domain = \"127.0.0.1.nip.io\" cmAddr = \"cm-chartmuseum.charts:8080\" } ... # make it stick git add . git commit -m \"set docker hub user\" git push Install Tiller for this app helm init --service-account build \\ --tiller-namespace aegjxnode-build Create Jenkins Cloud for this App If you look in the Jenkinsfile you will see a reference to aegjxnode-build . cd aegjxnode cat Jenkinsfile ... agent { kubernetes { cloud \"aegjxnode-build\" label \"aegjxnode-build\" serviceAccount \"build\" yamlFile \"KubernetesPod.yaml\" } ... To configure the cloud open the Jenkins UI and navigate to the /configure page. Please scroll to the bottom of the page, expand the Add a new cloud list, and select Kubernetes . A new set of fields will appear. Type aegjxnode-build as the name. It matches the cloud entry inside kubernetes block of our pipeline. Next, type aegjxnode-build as the Kubernetes Namespace. Just as with the other Kubernetes Cloud that was already defined in our Jenkins instance, the value of the Jenkins URL should be http://prod-jenkins.prod:8080 , and the Jenkins tunnel should be set to prod-jenkins-agent.prod:50000 . Sandbox To test a release: TODO - refer to step above once they quit changing TODO add verification steps","title":"aegjxnode"},{"location":"cicd/cicd-toolkit24/#deploy-environment","text":"One or more apps are owned by a team. Each team has a production environment such as team1-pord . The chart in the helm folder will reference all the apps that are required for this environment in requirements.yaml","title":"Deploy Environment"},{"location":"cicd/cicd-toolkit24/#manual-deploy","text":"Clone the environment chart and review the values. git clone https://github.com/tgilkerson/team1-prod.git cd team1-prod ls -l helm Verify the host address is correct in helm/values.yaml . go-demo-5: ingress: host: go-demo-5.127.0.0.1.nip.io aegjxnode: ingress: host: aegjxnode.127.0.0.1.nip.io Later on, we\u2019ll use Jenkins to install (or upgrade) the Chart, so we should push the changes to GitHub. git add . git commit -m \"Fix the address\" git push All Helm dependencies need to be downloaded to the charts directory before they are installed. We\u2019ll do that through the helm dependency update command. Don\u2019t worry if some of the repositories are not reachable. You might see messages stating that Helm was unable to get an update from local or chartmuseum repositories. First lets do a manually deploy of the team1-prod environment. cd team1-prod helm dependency update helm ls helm/charts/ # To confirm ls -l helm/charts # The output should look like this aegjxnode-0.1.9.tgz go-demo-5-0.0.1.tgz # The first time helm install helm --name team1-prod --namespace team1-prod # Or do this the -i will install if it does not exist helm upgrade -i team1-prod helm --namespace team1-prod # verify kubectl -n team1-prod rollout status deploy team1-prod-go-demo-5 curl go-demo-5.127.0.0.1.nip.io/demo/hello # clean up helm list helm delete team1-prod --purge Auto Deploy The CI/CD pipeline will automate the manual steps above.","title":"Manual Deploy"},{"location":"cicd/cicd-toolkit24/#jeninsx","text":"JenkinsX was not in the book, it is too new, however I did look into it a bit to take a look at their workflow. To install on my docker-for-windows cluster: Taken from getting started jx install --provider=kubernetes --on-premise Jenkins X installation completed successfully Your admin password is: =rvC9qvz0fq9is^Z6SwY -------------------------------------------------------------------------------- # Utility Some utility functions and other useful stuff to help debug. ```bash kubectl -n <target-namespace> run -it \\ --image ubuntu aegutil --restart=Never --rm sh # then you can... apt-get update apt-get install curl apt-get install iputils-ping","title":"JeninsX"},{"location":"cicd/jx-toolkit26/","text":"Create Cluster Notes taken form Viktor Farcic. The DevOps 2.6 Toolkit: Jenkins X leanpub.com Commands for this section: 02-intro.sh Install prerequisites tools See \"Manually install prerequisites (Kindle Location 99)\" for more detail: git (and gitbash) kubectl Helm AWS CLI and eksctl (for EKS) gcloud (for GKE) Azure CLI (for AKS) jq hub jenkins-x GitBash tweak To get the gcloud command to work in gitbash I had to add python to the path. If this does not work you can try just running the command in PowerShell. cd echo \"export PATH=$PATH:/c/Python27\" >> .bashrc # open a new shell Create Cluster with jx Disable Nexus I will not need Nexus most of the time so just turn it off. echo \"nexus: enabled: false\" | tee myvalues.yaml Create the cluster # If GKE PROJECT=\"aeg-jenkinsx\" JX_ENV=\"jxeMMDD\" # this changes each time # If GKE (note winpty is needed for gitbash) winpty jx create cluster gke \\ -n $JX_ENV \\ -p $PROJECT \\ -z us-east1-b \\ -m n1-standard-1 \\ --min-num-nodes 2 \\ --max-num-nodes 5 \\ --default-admin-password aegadmin \\ --default-environment-prefix $JX_ENV \\ --preemptible=true # why not I am just testing Destroy Cluster Remove the cluster and everything else. GH_USER=\"tonygilkerson\" hub delete -y $GH_USER/environment-$JX_ENV-staging hub delete -y $GH_USER/environment-$JX_ENV-production rm -rf ~/.jx/environments/$GH_USER/environment-$JX_ENV-* rm -f ~/.jx/jenkinsAuth.yaml # for gcp # Note for gitbash I needed to use winpty and add '.cmd' to the end of gcloud winpty gcloud.cmd container clusters delete $JX_ENV --zone us-east1-b # remove unused disks winpty gcloud.cmd compute disks delete \\ $(gcloud compute disks list \\ --filter=\"-users:*\" \\ --format=\"value(id)\") Exploring Quickstart Projects Create a sample project to see how things work. Commands for this section: 03-quickstart.sh Prerequisites Create a cluster as we did before, see Create Cluster Create project QS_PROJECT=\"jxqsMMDD\" # change this as needed winpty jx create quickstart -l go -p $QS_PROJECT -b Cleanup project Destroy Cluster as we did before. Then cleanup the quickstart app: hub delete -y $GH_USER/$QS_PROJECT # TODO need to verify cd .. rm -rf $QS_PROJECT","title":"Toolkit 2.6 JenkinX"},{"location":"cicd/jx-toolkit26/#create-cluster","text":"Notes taken form Viktor Farcic. The DevOps 2.6 Toolkit: Jenkins X leanpub.com Commands for this section: 02-intro.sh","title":"Create Cluster"},{"location":"cicd/jx-toolkit26/#install-prerequisites-tools","text":"See \"Manually install prerequisites (Kindle Location 99)\" for more detail: git (and gitbash) kubectl Helm AWS CLI and eksctl (for EKS) gcloud (for GKE) Azure CLI (for AKS) jq hub jenkins-x GitBash tweak To get the gcloud command to work in gitbash I had to add python to the path. If this does not work you can try just running the command in PowerShell. cd echo \"export PATH=$PATH:/c/Python27\" >> .bashrc # open a new shell","title":"Install prerequisites tools"},{"location":"cicd/jx-toolkit26/#create-cluster-with-jx","text":"Disable Nexus I will not need Nexus most of the time so just turn it off. echo \"nexus: enabled: false\" | tee myvalues.yaml Create the cluster # If GKE PROJECT=\"aeg-jenkinsx\" JX_ENV=\"jxeMMDD\" # this changes each time # If GKE (note winpty is needed for gitbash) winpty jx create cluster gke \\ -n $JX_ENV \\ -p $PROJECT \\ -z us-east1-b \\ -m n1-standard-1 \\ --min-num-nodes 2 \\ --max-num-nodes 5 \\ --default-admin-password aegadmin \\ --default-environment-prefix $JX_ENV \\ --preemptible=true # why not I am just testing","title":"Create Cluster with jx"},{"location":"cicd/jx-toolkit26/#destroy-cluster","text":"Remove the cluster and everything else. GH_USER=\"tonygilkerson\" hub delete -y $GH_USER/environment-$JX_ENV-staging hub delete -y $GH_USER/environment-$JX_ENV-production rm -rf ~/.jx/environments/$GH_USER/environment-$JX_ENV-* rm -f ~/.jx/jenkinsAuth.yaml # for gcp # Note for gitbash I needed to use winpty and add '.cmd' to the end of gcloud winpty gcloud.cmd container clusters delete $JX_ENV --zone us-east1-b # remove unused disks winpty gcloud.cmd compute disks delete \\ $(gcloud compute disks list \\ --filter=\"-users:*\" \\ --format=\"value(id)\")","title":"Destroy Cluster"},{"location":"cicd/jx-toolkit26/#exploring-quickstart-projects","text":"Create a sample project to see how things work. Commands for this section: 03-quickstart.sh Prerequisites Create a cluster as we did before, see Create Cluster","title":"Exploring Quickstart Projects"},{"location":"cicd/jx-toolkit26/#create-project","text":"QS_PROJECT=\"jxqsMMDD\" # change this as needed winpty jx create quickstart -l go -p $QS_PROJECT -b","title":"Create project"},{"location":"cicd/jx-toolkit26/#cleanup-project","text":"Destroy Cluster as we did before. Then cleanup the quickstart app: hub delete -y $GH_USER/$QS_PROJECT # TODO need to verify cd .. rm -rf $QS_PROJECT","title":"Cleanup project"},{"location":"decks/jx-accelerate-deck/","text":"Accelerate Deck This section contains the notes taken while watching the Accelerate your CI/CD on Kubernetes with Jenkins X (James Strachan) James Strachan recommends this book and says Jenkins X tries to adopt many of the principles in this book: Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations 7 Capabilities of Jenkins X Taken from the book here are 7 practices of high performing teams. Jenkins X uses open source software to automate these practices. 1. Use version control for all artifacts source code and code (IaC) when things go bad we can revert provides an audit trail 2. Use trunk-based development developers collaborate on code in a single branch called 'trunk'. They therefore avoid merge hell, do not break the build, and live happily ever after. the use of long-lived featured branches is associated with low performing teams trunk-based development is associated with high performing teams 6. Use loosely coupled architecture High performing teams use the cloud well to deliver highly available, multi-az deployments that are self healing and auto scaling. microservices allows teams to move quicker; many independent teams can move quicker than one large team. Kubernetes is ideal for running microservices. runs everywhere while providing a consistent abstraction across all cloud providers a single way to package applications and run them in any cloud (or on premise)! multi cloud is now achievable by mortals challenge: teams now need to figure out how to do many things well; microservices, cloud, Kubernetes, CI/CD, etc.. this is where Jenkins X comes in 3. Implement continuous integration (CI) 4. Implement continuous delivery (CD) 5. Automate your deployment process 7. Architect for empowered teams How does Jenkins X help? Automates the setup of your tools +environments Jenkins, helm, skaffold, nexus, monocular Automates the CI/CD for your application on Kubernetes Docker images Helm charts Jenkins Pipelines Uses GitOps to manage promotion between environments Test -> Staging -> Production use git as the source of truth for each environment; e.g. a prod repo will list all the microservices, the version of each and any environment specific configuration running in the prod environment could use kubectl to promote code to various environments but no one can see what you are doing, reverting back is not as easy and it is dangerous especially when you are trying to move fast. to promote between environments we use a PR. The team can code review/approve coding as well as configuration changes. An approved PR tells the team what is in prod and when it was installed. And, if things go bad, just revert the PR to roll back. Lots of feedback E.g. commenting on issues as they hit Staging + Production Installing Jenkins X Install the jx binary https://jenkins-x.io/geting-started/install/ Createa new k8scluster on GKE $ jx create cluster gke As of now, supported clouds: create cluster aks Create a new Kubernetes cluster on AKS: Runs on Azure create cluster aws Create a new Kubernetes cluster on AWS with kops create cluster eks Create a new Kubernetes cluster on AWS using EKS create cluster gke Create a new Kubernetes cluster on GKE: Runs on Google Cloud create cluster iks Create a new kubernetes cluster on IBM Cloud Kubernetes Services create cluster minikube Create a new Kubernetes cluster with Minikube: Runs locally create cluster minishift Create a new OpenShift cluster with Minishift: Runs locally create cluster oke Create a new Kubernetes cluster on OKE: Runs on Oracle Cloud Install Jenkins X on an existing cluster $ jx install --provider=... What does that give me? Each team gets their own: Development tools environment Jenkins master Elastic pool of Kubernetes build pods Nexus + Monocular (helm application store) Staging environment Production environment Also... This empowers each team to work independently and release when they want Can configure more environments but out-of-the-box you get one staging and one production environment. A new version is released for each PR merged to 'trunk' Each release is automatically promoted to staging but requires a manual step to promote to production by default. This can be changed for 100% automation. Importing and Creating Projects Import existing If you already have some code. $ jx import Create new applications from quickstarts This is preferred so you know everything is setup correctly. The import works but you never know. $ jx create quickstart there are a bunch of quick starts they are open source so you can check them out here There is one for most of the popular development platforms You can create a custom template if you like Create new Spring Boot applications $ jx create spring What you get from a quickstart jx create will... Create a project repo GitHub Create a dockerfile Create a helm chart Create environment repos in GitHub (staging and production) Setup all the webhooks in GitHub Setup all your CI/CD (Jenkins pipelines)","title":"Jenkins X Accelerate Deck"},{"location":"decks/jx-accelerate-deck/#accelerate-deck","text":"This section contains the notes taken while watching the Accelerate your CI/CD on Kubernetes with Jenkins X (James Strachan) James Strachan recommends this book and says Jenkins X tries to adopt many of the principles in this book: Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations","title":"Accelerate Deck"},{"location":"decks/jx-accelerate-deck/#7-capabilities-of-jenkins-x","text":"Taken from the book here are 7 practices of high performing teams. Jenkins X uses open source software to automate these practices. 1. Use version control for all artifacts source code and code (IaC) when things go bad we can revert provides an audit trail 2. Use trunk-based development developers collaborate on code in a single branch called 'trunk'. They therefore avoid merge hell, do not break the build, and live happily ever after. the use of long-lived featured branches is associated with low performing teams trunk-based development is associated with high performing teams 6. Use loosely coupled architecture High performing teams use the cloud well to deliver highly available, multi-az deployments that are self healing and auto scaling. microservices allows teams to move quicker; many independent teams can move quicker than one large team. Kubernetes is ideal for running microservices. runs everywhere while providing a consistent abstraction across all cloud providers a single way to package applications and run them in any cloud (or on premise)! multi cloud is now achievable by mortals challenge: teams now need to figure out how to do many things well; microservices, cloud, Kubernetes, CI/CD, etc.. this is where Jenkins X comes in 3. Implement continuous integration (CI) 4. Implement continuous delivery (CD) 5. Automate your deployment process 7. Architect for empowered teams","title":"7 Capabilities of Jenkins X"},{"location":"decks/jx-accelerate-deck/#how-does-jenkins-x-help","text":"Automates the setup of your tools +environments Jenkins, helm, skaffold, nexus, monocular Automates the CI/CD for your application on Kubernetes Docker images Helm charts Jenkins Pipelines Uses GitOps to manage promotion between environments Test -> Staging -> Production use git as the source of truth for each environment; e.g. a prod repo will list all the microservices, the version of each and any environment specific configuration running in the prod environment could use kubectl to promote code to various environments but no one can see what you are doing, reverting back is not as easy and it is dangerous especially when you are trying to move fast. to promote between environments we use a PR. The team can code review/approve coding as well as configuration changes. An approved PR tells the team what is in prod and when it was installed. And, if things go bad, just revert the PR to roll back. Lots of feedback E.g. commenting on issues as they hit Staging + Production","title":"How does Jenkins X help?"},{"location":"decks/jx-accelerate-deck/#installing-jenkins-x","text":"Install the jx binary https://jenkins-x.io/geting-started/install/ Createa new k8scluster on GKE $ jx create cluster gke As of now, supported clouds: create cluster aks Create a new Kubernetes cluster on AKS: Runs on Azure create cluster aws Create a new Kubernetes cluster on AWS with kops create cluster eks Create a new Kubernetes cluster on AWS using EKS create cluster gke Create a new Kubernetes cluster on GKE: Runs on Google Cloud create cluster iks Create a new kubernetes cluster on IBM Cloud Kubernetes Services create cluster minikube Create a new Kubernetes cluster with Minikube: Runs locally create cluster minishift Create a new OpenShift cluster with Minishift: Runs locally create cluster oke Create a new Kubernetes cluster on OKE: Runs on Oracle Cloud Install Jenkins X on an existing cluster $ jx install --provider=...","title":"Installing Jenkins X"},{"location":"decks/jx-accelerate-deck/#what-does-that-give-me","text":"Each team gets their own: Development tools environment Jenkins master Elastic pool of Kubernetes build pods Nexus + Monocular (helm application store) Staging environment Production environment Also... This empowers each team to work independently and release when they want Can configure more environments but out-of-the-box you get one staging and one production environment. A new version is released for each PR merged to 'trunk' Each release is automatically promoted to staging but requires a manual step to promote to production by default. This can be changed for 100% automation.","title":"What does that give me?"},{"location":"decks/jx-accelerate-deck/#importing-and-creating-projects","text":"Import existing If you already have some code. $ jx import Create new applications from quickstarts This is preferred so you know everything is setup correctly. The import works but you never know. $ jx create quickstart there are a bunch of quick starts they are open source so you can check them out here There is one for most of the popular development platforms You can create a custom template if you like Create new Spring Boot applications $ jx create spring","title":"Importing and Creating Projects"},{"location":"decks/jx-accelerate-deck/#what-you-get-from-a-quickstart","text":"jx create will... Create a project repo GitHub Create a dockerfile Create a helm chart Create environment repos in GitHub (staging and production) Setup all the webhooks in GitHub Setup all your CI/CD (Jenkins pipelines)","title":"What you get from a quickstart"},{"location":"decks/jx-intro/jx-intro/","text":"Introduction What's Included in this Article Deck - A short presentation to... set context and state a Software Delivery vision Demo - Demonstrate development capabilities; quick-start apps custom quick-start apps cloud based dev sandbox What's Left for a Future Article Metrics Alerting/SLA Auto Scaling How to be a High Preforming Team Armed with robust data-gathering and statistical analysis techniques, we have been able to discover significant results while working on the State of DevOps Report. We\u2019ve been able to measure and quantify software delivery performance, its impact on organizational performance, and the various capabilities that contribute to these outcomes. The key to successful change is measuring and understanding the right things with a focus on capabilities \u2014not on maturity. Approach Based on Industry Research Quotes above from the book: Forsgren PhD, Nicole. Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations Many ideas presented here are based on the principles in this book. Also technical details presented here are based on the book: Viktor Farcic. The DevOps 2.6 Toolkit: Jenkins X leanpub.com and 02-intro.sh Software Delivery Development - Areas where Dev and Ops need to work together; Branching strategy Quickstarts - 0 to live in 5! (see demo) Testing, Development and Promotion tools CI/CD Auto-scaling CI/CD runners GitOps/IaC that is Cloud Neutral (same process for AWS, Azure, GCP or on-premise) Environments (PR preview, Staging, Production) Day 2 - Ongoing support and maintenance after going live Monitoring, Alerting, Metrics, Visibility, SLOs/SLAs, etc... Upgrades and patching Operations Management (on call support) Deployment Platform Run-time platform (Kubernetes) - a \"run anywhere\" platform with facilities for deploying and running a variety of workload Service discovery, load balancing Self-healing Storage orchestration Automated rollouts and rollbacks Automatic binpacking Horizontal scaling Batch execution Customer Environment (Helm) - Customer preview, staging and production environments that host client applications A Helm chart used to describe the applications and all its dependancies Chart configuration provide repeatable application installation and serve as a single point of authority Versioned, in source control and portable Metrics (Prometheus) - Time-series database for collecting application and system metrics Dimensional data in a time series database PromQL - query language for defining alerts or ad-hoc graphs and reports Alert Manager - Handles alerts performing functions such as deduplication, grouping routing to correct receiver Slack, email, PagerDuty, etc... Ops Visibility (Grafana) - Visualization tool for building dashboards that help you understand your metrics Auto Scaler (HPA) - Ability to scale applications based on CPU or RAM utilization or custom thresholds defined using collected metrics Ops Management (PagerDuty) - Incident and on-call management service Log Management (Papertrail) - Centralized log aggregation service in Papertrail or cloud provider. Infrastructure (GCP) - Public cloud or in-premises infrastructure. GCP, AWS, Azure, etc.. Jenkins X 7 Capabilities of Jenkins X Taken from the Accelerate book here are 7 practices of high performing teams. Jenkins X uses open source software to automate these practices. 1. Use version control for all artifacts source code and code (IaC) when things go bad we can revert provides an audit trail 2. Use trunk-based development developers collaborate on code in a single branch called 'trunk'. They therefore avoid merge hell, do not break the build, and avoid conflicts. the use of long-lived featured branches is associated with low performing teams trunk-based development is associated with high performing teams 3. Use loosely coupled architecture High performing teams use the cloud well to deliver highly available, multi-az deployments that are self healing and auto scaling. microservices allows teams to move quicker; many independent teams can move quicker than one large team. Kubernetes is ideal for running microservices. runs everywhere while providing a consistent abstraction across all cloud providers a single way to package applications and run them in any cloud (or on premise)! multi cloud is now achievable by mortals challenge: teams now need to figure out how to do many things well; microservices, cloud, Kubernetes, CI/CD, etc.. this is where Jenkins X comes in 4. Implement continuous integration (CI) 5. Implement continuous delivery (CD) 6. Automate your deployment process 7. Architect for empowered teams How does Jenkins X help? Automates the setup of your tools + environments Jenkins, helm, skaffold, nexus, monocular Developer not require to be an expert in Ops stack (but it helps!) Automates the CI/CD for your application on Kubernetes Docker images Helm charts Jenkins Pipelines Uses GitOps to manage promotion between environments automated promotion; Test -> Staging -> Production use PR to promote between environments. The team can code review/approve coding as well as configuration changes an approved PR tells the team what is in prod and when it was installed. And, if things go bad, just revert the PR to roll back. could use CLI tools to promote code to various environments but no one can see what you are doing, reverting back is not easy and it is dangerous especially when you are trying to move fast use git as the source of truth for each environment a source repo will list all the microservices, the version of each and any environment specific configuration running in the prod environment Lots of feedback E.g. commenting on issues as they hit Staging + Production Jenkins X Overview Install the jx binary https://jenkins-x.io/geting-started/install/ Create a new k8s cluster on GKE $ jx create cluster gke As of now, supported clouds: create cluster aks Create a new Kubernetes cluster on AKS: Runs on Azure create cluster aws Create a new Kubernetes cluster on AWS with kops create cluster eks Create a new Kubernetes cluster on AWS using EKS create cluster gke Create a new Kubernetes cluster on GKE: Runs on Google Cloud create cluster iks Create a new kubernetes cluster on IBM Cloud Kubernetes Services create cluster minikube Create a new Kubernetes cluster with Minikube: Runs locally create cluster minishift Create a new OpenShift cluster with Minishift: Runs locally create cluster oke Create a new Kubernetes cluster on OKE: Runs on Oracle Cloud Install Jenkins X on an existing cluster $ jx install --provider=... What does that give me? Each team gets their own: Development tools environment Jenkins master Elastic pool of Kubernetes build pods Helm + Monocular Staging environment Production environment Also... This empowers each team to work independently and release when they want Can configure more environments but out-of-the-box you get one staging and one production environment. A new version is released for each PR merged to 'trunk' Each release is automatically promoted to staging but requires a manual step to promote to production by default. This can be changed for 100% automation. Importing and Creating Projects Import existing If you already have some code. $ jx import Create new applications from quickstarts This is preferred so you know everything is setup correctly. The import works but you never know. $ jx create quickstart there are a bunch of quick starts they are open source so you can check them out here There is one for most of the popular development platforms You can create a custom template if you like What you get from a quickstart jx create will... Create a project repo GitHub Create a dockerfile Create a helm chart Create environment repos in GitHub (staging and production) Setup all the webhooks in GitHub Setup all your CI/CD (Jenkins pipelines) For examlle, this will create a Simple Hello World node.js appliation that listens on localhost:8080 $ jx create quickstart node-http Quickstart Demo Prerequisite Tools It is up to you to figure out how to install the following tools. The general approach is to go to the source and follow their instruction. In other cases brew will work. git (and gitbash) kubectl Helm AWS CLI and eksctl (for EKS) gcloud (for GKE) Azure CLI (for AKS) jq hub Jenkins X CLI For macOS: brew tap jenkins-x/jx brew install jx Create Cluster with jx Disable Nexus We will not need Nexus let's just turn it off. echo \"nexus: enabled: false\" | tee myvalues.yaml Create the cluster # If GKE PROJECT=\"aeg-jenkinsx\" JX_ENV=\"jxeMMDD\" # change this each as needed jx create cluster gke \\ -n $JX_ENV \\ -p $PROJECT \\ -z us-east1-b \\ -m n1-standard-1 \\ --min-num-nodes 2 \\ --max-num-nodes 5 \\ --default-admin-password aegadmin \\ --default-environment-prefix $JX_ENV \\ --preemptible=true # if testing # The browser will open so you can authenticate with google cloud # Then you will be prompted for a few things, here are my responses: ? Would you like to access Google Cloud Storage / Google Container Registry? Yes ? Would you like to enable Cloud Build, Container Registry & Container Analysis APIs? No ? Would you like to enable Kaniko for building container images No ? No existing ingress controller found in the kube-system namespace, shall we install one? Yes ? A local Jenkins X versions repository already exists, recreate with latest? Yes ? Domain 34.73.130.212.nip.io Create Quickstart Project Create a sample project to see how things work. Commands for this section have been adapted from the book: 03-quickstart.sh Create a cluster as we did before, see Create Cluster . Then create the project. Create project QS_PROJECT=\"jxqsMMDD\" # change this as needed jx create quickstart -l go -p $QS_PROJECT -b jx get activities Cleanup Destroy Cluster Remove the cluster and everything else. GH_USER=\"tgilkerson\" hub delete -y $GH_USER/environment-$JX_ENV-staging hub delete -y $GH_USER/environment-$JX_ENV-production rm -rf ~/.jx/environments/$GH_USER/environment-$JX_ENV-* rm -f ~/.jx/jenkinsAuth.yaml gcloud container clusters delete $JX_ENV --zone us-east1-b # remove unused disks gcloud compute disks delete \\ $(gcloud compute disks list \\ --filter=\"-users:*\" \\ --format=\"value(id)\") Cleanup project hub delete -y $GH_USER/$QS_PROJECT cd .. rm -rf $QS_PROJECT","title":"Jenkins X intro"},{"location":"decks/jx-intro/jx-intro/#introduction","text":"","title":"Introduction"},{"location":"decks/jx-intro/jx-intro/#whats-included-in-this-article","text":"Deck - A short presentation to... set context and state a Software Delivery vision Demo - Demonstrate development capabilities; quick-start apps custom quick-start apps cloud based dev sandbox","title":"What's  Included in this Article"},{"location":"decks/jx-intro/jx-intro/#whats-left-for-a-future-article","text":"Metrics Alerting/SLA Auto Scaling","title":"What's Left for a Future Article"},{"location":"decks/jx-intro/jx-intro/#how-to-be-a-high-preforming-team","text":"Armed with robust data-gathering and statistical analysis techniques, we have been able to discover significant results while working on the State of DevOps Report. We\u2019ve been able to measure and quantify software delivery performance, its impact on organizational performance, and the various capabilities that contribute to these outcomes. The key to successful change is measuring and understanding the right things with a focus on capabilities \u2014not on maturity.","title":"How to be a High Preforming Team"},{"location":"decks/jx-intro/jx-intro/#approach-based-on-industry-research","text":"Quotes above from the book: Forsgren PhD, Nicole. Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations Many ideas presented here are based on the principles in this book. Also technical details presented here are based on the book: Viktor Farcic. The DevOps 2.6 Toolkit: Jenkins X leanpub.com and 02-intro.sh","title":"Approach Based on Industry Research"},{"location":"decks/jx-intro/jx-intro/#software-delivery","text":"Development - Areas where Dev and Ops need to work together; Branching strategy Quickstarts - 0 to live in 5! (see demo) Testing, Development and Promotion tools CI/CD Auto-scaling CI/CD runners GitOps/IaC that is Cloud Neutral (same process for AWS, Azure, GCP or on-premise) Environments (PR preview, Staging, Production) Day 2 - Ongoing support and maintenance after going live Monitoring, Alerting, Metrics, Visibility, SLOs/SLAs, etc... Upgrades and patching Operations Management (on call support)","title":"Software Delivery"},{"location":"decks/jx-intro/jx-intro/#deployment-platform","text":"Run-time platform (Kubernetes) - a \"run anywhere\" platform with facilities for deploying and running a variety of workload Service discovery, load balancing Self-healing Storage orchestration Automated rollouts and rollbacks Automatic binpacking Horizontal scaling Batch execution Customer Environment (Helm) - Customer preview, staging and production environments that host client applications A Helm chart used to describe the applications and all its dependancies Chart configuration provide repeatable application installation and serve as a single point of authority Versioned, in source control and portable Metrics (Prometheus) - Time-series database for collecting application and system metrics Dimensional data in a time series database PromQL - query language for defining alerts or ad-hoc graphs and reports Alert Manager - Handles alerts performing functions such as deduplication, grouping routing to correct receiver Slack, email, PagerDuty, etc... Ops Visibility (Grafana) - Visualization tool for building dashboards that help you understand your metrics Auto Scaler (HPA) - Ability to scale applications based on CPU or RAM utilization or custom thresholds defined using collected metrics Ops Management (PagerDuty) - Incident and on-call management service Log Management (Papertrail) - Centralized log aggregation service in Papertrail or cloud provider. Infrastructure (GCP) - Public cloud or in-premises infrastructure. GCP, AWS, Azure, etc..","title":"Deployment Platform"},{"location":"decks/jx-intro/jx-intro/#jenkins-x","text":"","title":"Jenkins X"},{"location":"decks/jx-intro/jx-intro/#7-capabilities-of-jenkins-x","text":"Taken from the Accelerate book here are 7 practices of high performing teams. Jenkins X uses open source software to automate these practices. 1. Use version control for all artifacts source code and code (IaC) when things go bad we can revert provides an audit trail 2. Use trunk-based development developers collaborate on code in a single branch called 'trunk'. They therefore avoid merge hell, do not break the build, and avoid conflicts. the use of long-lived featured branches is associated with low performing teams trunk-based development is associated with high performing teams 3. Use loosely coupled architecture High performing teams use the cloud well to deliver highly available, multi-az deployments that are self healing and auto scaling. microservices allows teams to move quicker; many independent teams can move quicker than one large team. Kubernetes is ideal for running microservices. runs everywhere while providing a consistent abstraction across all cloud providers a single way to package applications and run them in any cloud (or on premise)! multi cloud is now achievable by mortals challenge: teams now need to figure out how to do many things well; microservices, cloud, Kubernetes, CI/CD, etc.. this is where Jenkins X comes in 4. Implement continuous integration (CI) 5. Implement continuous delivery (CD) 6. Automate your deployment process 7. Architect for empowered teams","title":"7 Capabilities of Jenkins X"},{"location":"decks/jx-intro/jx-intro/#how-does-jenkins-x-help","text":"Automates the setup of your tools + environments Jenkins, helm, skaffold, nexus, monocular Developer not require to be an expert in Ops stack (but it helps!) Automates the CI/CD for your application on Kubernetes Docker images Helm charts Jenkins Pipelines Uses GitOps to manage promotion between environments automated promotion; Test -> Staging -> Production use PR to promote between environments. The team can code review/approve coding as well as configuration changes an approved PR tells the team what is in prod and when it was installed. And, if things go bad, just revert the PR to roll back. could use CLI tools to promote code to various environments but no one can see what you are doing, reverting back is not easy and it is dangerous especially when you are trying to move fast use git as the source of truth for each environment a source repo will list all the microservices, the version of each and any environment specific configuration running in the prod environment Lots of feedback E.g. commenting on issues as they hit Staging + Production","title":"How does Jenkins X help?"},{"location":"decks/jx-intro/jx-intro/#jenkins-x-overview","text":"Install the jx binary https://jenkins-x.io/geting-started/install/ Create a new k8s cluster on GKE $ jx create cluster gke As of now, supported clouds: create cluster aks Create a new Kubernetes cluster on AKS: Runs on Azure create cluster aws Create a new Kubernetes cluster on AWS with kops create cluster eks Create a new Kubernetes cluster on AWS using EKS create cluster gke Create a new Kubernetes cluster on GKE: Runs on Google Cloud create cluster iks Create a new kubernetes cluster on IBM Cloud Kubernetes Services create cluster minikube Create a new Kubernetes cluster with Minikube: Runs locally create cluster minishift Create a new OpenShift cluster with Minishift: Runs locally create cluster oke Create a new Kubernetes cluster on OKE: Runs on Oracle Cloud Install Jenkins X on an existing cluster $ jx install --provider=...","title":"Jenkins X Overview"},{"location":"decks/jx-intro/jx-intro/#what-does-that-give-me","text":"Each team gets their own: Development tools environment Jenkins master Elastic pool of Kubernetes build pods Helm + Monocular Staging environment Production environment Also... This empowers each team to work independently and release when they want Can configure more environments but out-of-the-box you get one staging and one production environment. A new version is released for each PR merged to 'trunk' Each release is automatically promoted to staging but requires a manual step to promote to production by default. This can be changed for 100% automation.","title":"What does that give me?"},{"location":"decks/jx-intro/jx-intro/#importing-and-creating-projects","text":"Import existing If you already have some code. $ jx import Create new applications from quickstarts This is preferred so you know everything is setup correctly. The import works but you never know. $ jx create quickstart there are a bunch of quick starts they are open source so you can check them out here There is one for most of the popular development platforms You can create a custom template if you like","title":"Importing and Creating Projects"},{"location":"decks/jx-intro/jx-intro/#what-you-get-from-a-quickstart","text":"jx create will... Create a project repo GitHub Create a dockerfile Create a helm chart Create environment repos in GitHub (staging and production) Setup all the webhooks in GitHub Setup all your CI/CD (Jenkins pipelines) For examlle, this will create a Simple Hello World node.js appliation that listens on localhost:8080 $ jx create quickstart node-http","title":"What you get from a quickstart"},{"location":"decks/jx-intro/jx-intro/#quickstart-demo","text":"","title":"Quickstart Demo"},{"location":"decks/jx-intro/jx-intro/#prerequisite-tools","text":"It is up to you to figure out how to install the following tools. The general approach is to go to the source and follow their instruction. In other cases brew will work. git (and gitbash) kubectl Helm AWS CLI and eksctl (for EKS) gcloud (for GKE) Azure CLI (for AKS) jq hub Jenkins X CLI For macOS: brew tap jenkins-x/jx brew install jx","title":"Prerequisite Tools"},{"location":"decks/jx-intro/jx-intro/#create-cluster-with-jx","text":"Disable Nexus We will not need Nexus let's just turn it off. echo \"nexus: enabled: false\" | tee myvalues.yaml Create the cluster # If GKE PROJECT=\"aeg-jenkinsx\" JX_ENV=\"jxeMMDD\" # change this each as needed jx create cluster gke \\ -n $JX_ENV \\ -p $PROJECT \\ -z us-east1-b \\ -m n1-standard-1 \\ --min-num-nodes 2 \\ --max-num-nodes 5 \\ --default-admin-password aegadmin \\ --default-environment-prefix $JX_ENV \\ --preemptible=true # if testing # The browser will open so you can authenticate with google cloud # Then you will be prompted for a few things, here are my responses: ? Would you like to access Google Cloud Storage / Google Container Registry? Yes ? Would you like to enable Cloud Build, Container Registry & Container Analysis APIs? No ? Would you like to enable Kaniko for building container images No ? No existing ingress controller found in the kube-system namespace, shall we install one? Yes ? A local Jenkins X versions repository already exists, recreate with latest? Yes ? Domain 34.73.130.212.nip.io","title":"Create Cluster with jx"},{"location":"decks/jx-intro/jx-intro/#create-quickstart-project","text":"Create a sample project to see how things work. Commands for this section have been adapted from the book: 03-quickstart.sh Create a cluster as we did before, see Create Cluster . Then create the project.","title":"Create Quickstart Project"},{"location":"decks/jx-intro/jx-intro/#create-project","text":"QS_PROJECT=\"jxqsMMDD\" # change this as needed jx create quickstart -l go -p $QS_PROJECT -b jx get activities","title":"Create project"},{"location":"decks/jx-intro/jx-intro/#cleanup","text":"","title":"Cleanup"},{"location":"decks/jx-intro/jx-intro/#destroy-cluster","text":"Remove the cluster and everything else. GH_USER=\"tgilkerson\" hub delete -y $GH_USER/environment-$JX_ENV-staging hub delete -y $GH_USER/environment-$JX_ENV-production rm -rf ~/.jx/environments/$GH_USER/environment-$JX_ENV-* rm -f ~/.jx/jenkinsAuth.yaml gcloud container clusters delete $JX_ENV --zone us-east1-b # remove unused disks gcloud compute disks delete \\ $(gcloud compute disks list \\ --filter=\"-users:*\" \\ --format=\"value(id)\")","title":"Destroy Cluster"},{"location":"decks/jx-intro/jx-intro/#cleanup-project","text":"hub delete -y $GH_USER/$QS_PROJECT cd .. rm -rf $QS_PROJECT","title":"Cleanup project"}]}